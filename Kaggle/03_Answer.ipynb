{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Answer.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Hgp6rgtLqGxe","colab_type":"text"},"cell_type":"markdown","source":["![](https://cdn-images-1.medium.com/max/1600/1*jX6Gwn1rt4da7e-yUj84IQ.png)\n","\n","### 這只是對分類特徵做 Likelihood Encoding \n","\n","### 也稱為Impact Encoding 或 Mean Encoding 或 Target Encoding。\n","\n"]},{"metadata":{"id":"yYtah12ZqGxf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import KFold"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2pf-UUq9qGxj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["PATH = 'data/'\n","train_data = pd.read_table(PATH + 'train.tsv', engine='c')\n","train_data.rename(index=str, columns={'price':'y'},inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JQjM6m3WqGxl","colab_type":"text"},"cell_type":"markdown","source":["# 抓出Category dtypes"]},{"metadata":{"id":"naLcIH0xqGxm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"6b137c1f-6bc5-4caa-e6df-f8e9eaa5044c"},"cell_type":"code","source":["categorical_features = []\n","\n","for dtype, feature in zip(train_data.dtypes, train_data.columns):\n","    if dtype == object:\n","        categorical_features.append(feature)\n","\n","categorical_features"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['name', 'category_name', 'brand_name', 'item_description']"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"HEeCIDtbqGxs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"5dd6a32c-05fa-40e9-e435-297cacf292f9"},"cell_type":"code","source":["for f_ in categorical_features:   \n","    print('{} has {} unique items'.format(f_, train_data[f_].nunique()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["name has 1225273 unique items\n","category_name has 1287 unique items\n","brand_name has 4809 unique items\n","item_description has 1281426 unique items\n"],"name":"stdout"}]},{"metadata":{"id":"0NsKU24bqGxu","colab_type":"text"},"cell_type":"markdown","source":["## name, item_description 是文字特徵，所以不能算在內\n","- 請記住 **band_name** 缺失值多達42%，本不應該拿去做target encoding\n","- 為了教學，我們先移除這些NaN"]},{"metadata":{"id":"YeepRs_LqGxw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"d2ed2353-2914-430e-bef4-ffdd561bbedf"},"cell_type":"code","source":["train_data = train_data[train_data['brand_name'].notnull()]\n","train_data = train_data[train_data['category_name'].notnull()]\n","\n","\n","categorical_features.remove('name')\n","categorical_features.remove('item_description')\n","categorical_features"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['category_name', 'brand_name']"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"GyyXfhW2qGxz","colab_type":"text"},"cell_type":"markdown","source":["# Mean encodings without regularization\n","   - 範例1"]},{"metadata":{"id":"ZkpqUSOlqGxz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"c1a3a778-4606-41d5-8de5-e59510bc2f3e"},"cell_type":"code","source":["for f_ in categorical_features:    \n","    global_mean = train_data['y'].mean()\n","    # Calculate a mapping: {item_id: target_mean}\n","    item_id_target_mean = train_data.groupby(f_).y.mean()\n","\n","    # In our non-regularized case we just *map* the computed means to the `item_id`'s\n","    train_data['item_target_enc'] = train_data[f_].map(item_id_target_mean)\n","\n","    # Fill NaNs\n","    train_data['item_target_enc'].fillna(global_mean, inplace=True) \n","\n","    # Print correlation\n","    encoded_feature = train_data['item_target_enc'].values\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.4465404391861943\n","Corr between brand_name and target is: 0.48512436987737967\n"],"name":"stdout"}]},{"metadata":{"id":"sO0ZcN1IqGx3","colab_type":"text"},"cell_type":"markdown","source":["   - 範例2"]},{"metadata":{"id":"4bPa8MZNqGx3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"7b69da5d-fea3-46a1-fbe7-42c5d532a7c4"},"cell_type":"code","source":["for f_ in categorical_features:    \n","    global_mean = train_data['y'].mean()\n","    # Calculate a mapping: {item_id: target_mean}\n","    item_id_target_mean = train_data.groupby(f_).y.mean()\n","    train_data['item_target_enc'] = train_data.groupby(f_)['y'].transform('mean')\n","\n","    # Fill NaNs\n","    train_data['item_target_enc'].fillna(global_mean, inplace=True) \n","\n","    # Print correlation\n","    encoded_feature = train_data['item_target_enc'].values\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.4465404391861943\n","Corr between brand_name and target is: 0.48512436987737967\n"],"name":"stdout"}]},{"metadata":{"id":"Jo_jLzkNqGx7","colab_type":"text"},"cell_type":"markdown","source":["# 練習時間：\n","## Mean encodings with Regularization\n","###   1. 引入regularization 避免 Overfitting\n","    - 此Regularization並不是L1, L2 Penalty\n","    \n","###   2. 參考指標，檢視跟Target的相關性。 \n","   - 謹記，您的作業的相關性，不應該高過全域的相關性，就是範例1, 2的相關性\n","   - 謹記，低於全域的相關性，不等於一定不會Overfitting\n","   \n","### 3. 請基於 範例1 or 範例2 完成以下\n","1. KFold scheme\n","2. Smoothing\n","3. Smoothing and noising\n","\n","### 4. 練習題採取雙刀流，即簡單的「兩行內」就可以搞定。"]},{"metadata":{"id":"c-4lrJZ_qGx9","colab_type":"text"},"cell_type":"markdown","source":["## 1. KFold scheme\n","\n","- Hint: 本例，在測試是否了解kold機制，因為之後很多練習都是基於Kfold，去做處理，請學員務必務必弄懂。\n","- 作法：假設切成N個fold，每次fold loop 取(N-1)份fold 資訊，去套用在剩下的那一份，vice versa.\n","- 只有兩行\n","    - 第一行：指派切割位置\n","    - 第二行：使用條件取代，套用在範例1 or 2 方法\n","\n","您可能會用到，**pandas conditional replace** (google it)"]},{"metadata":{"id":"bVF5wWqCqGx-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"4bd8825e-260e-4668-b53b-63a3710e4ce1"},"cell_type":"code","source":["# YOUR CODE GOES HERE\n","from sklearn.model_selection import KFold\n","kf = KFold(n_splits = 5, shuffle = False) \n","global_mean = train_data['y'].mean()\n","\n","for f_ in categorical_features:    \n","    \n","    train_data['item_target_enc'] = np.nan\n","    for tr_ind, val_ind in kf.split(train_data):\n","        X_tr, X_val = train_data.iloc[tr_ind], train_data.iloc[val_ind]\n","        train_data.loc[train_data.index[val_ind], 'item_target_enc'] = X_val[f_ ].map(X_tr.groupby(f_ ).y.mean())\n","\n","    train_data['item_target_enc'].fillna(global_mean, inplace = True)\n","    encoded_feature = train_data['item_target_enc'].values\n","    # You will need to compute correlation like that\n","    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.4448439052519598\n","Corr between brand_name and target is: 0.4778697947432403\n"],"name":"stdout"}]},{"metadata":{"id":"XISbA2joqGyD","colab_type":"text"},"cell_type":"markdown","source":["## 2. Smoothing\n","#### Hint:\n","- 第一行：請參考Slide數學公式的分子\n","    - 您可能會用到 `np.multiply` \n","- 第二行：請參考Slide數學公式的分母"]},{"metadata":{"id":"6kjEm96sqGyD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"f878f3ed-1731-4700-fffc-7431c789efed"},"cell_type":"code","source":["# YOUR CODE GOES HERE\n","alpha = 10\n","global_mean = train_data['y'].mean()\n","\n","for f_ in categorical_features:    \n","\n","    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n","    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n","    train_data['item_target_enc_smg'] = np.multiply(train_data['item_target_mean'] ,train_data['target_count'] ) + global_mean * alpha\n","    train_data['item_target_enc_smg'] = train_data['item_target_enc_smg'] / (train_data['target_count'] + alpha)\n","\n","    encoded_feature = train_data['item_target_enc_smg'].values\n","    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.4462495699282723\n","Corr between brand_name and target is: 0.4819742303440905\n"],"name":"stdout"}]},{"metadata":{"id":"qFMZzUKcqGyI","colab_type":"text"},"cell_type":"markdown","source":["## 2-1. Smoothing paper [Daniele Micci-Barreca](https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf)\n","- Hint:\n","1. 練習題的 Equation 4 解釋: \n","    - n 為 個數，\n","    - k 為 min_samples_leaf（設好了，可自行調整）\n","    - f 為 smoothing（設好了，可自行調整）\n","2. 練習題的 Equation 5 解釋: \n","    - B 為 smoothing\n","    - y head 以及 y 為 ？您應該要想想"]},{"metadata":{"id":"106YCNABqGyI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"a1c1ab7d-f7eb-4000-b299-b4e88ca88412"},"cell_type":"code","source":["\n","global_mean = train_data['y'].mean()\n","smoothing= 5\n","min_samples_leaf=100\n","\n","for f_ in categorical_features:    \n","\n","    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n","    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n","    # YOUR CODE GOES HERE \n","    \n","    # Please refer Paper equation 4\n","    smoothing = 1 / (1 + np.exp(-(train_data['target_count'] - min_samples_leaf) / smoothing))\n","    \n","    # Please refer Paper equation 5\n","    train_data['item_target_enc_smg'] = global_mean * (1 - smoothing) + train_data['item_target_mean'] * smoothing\n","    \n","    encoded_feature = train_data['item_target_enc_smg'].values\n","    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.4439601079786596\n","Corr between brand_name and target is: 0.4569492306386533\n"],"name":"stdout"},{"output_type":"stream","text":["/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n","  del sys.path[0]\n"],"name":"stderr"}]},{"metadata":{"id":"AZNa0PazqGyL","colab_type":"text"},"cell_type":"markdown","source":["## 3. Smoothing and Noising"]},{"metadata":{"id":"G8osa-K7qGyM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"23b4f035-d007-4bb3-e16d-0500896bd7e7"},"cell_type":"code","source":["# YOUR CODE GOES HERE\n","Factor = 100\n","global_mean = train_data['y'].mean()\n","noise_level = 0.05 # 可以調整這裡 (standard dev)\n","\n","for f_ in categorical_features:    \n","\n","    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n","    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n","    train_data['item_target_enc_smg'] = np.multiply(train_data['item_target_mean'] ,train_data['target_count'] ) + global_mean * Factor\n","    train_data['item_target_enc_smg'] = train_data['item_target_enc_smg'] / (train_data['target_count'] + Factor)\n","\n","    encoded_feature = train_data['item_target_enc_smg'].values* (1 + noise_level * np.random.randn(len(train_data)))\n","    \n","    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n","    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Corr between category_name and target is: 0.44202618398822685\n","Corr between brand_name and target is: 0.4662600752389201\n"],"name":"stdout"}]},{"metadata":{"id":"0H247-xVqGyP","colab_type":"text"},"cell_type":"markdown","source":["## 4. CV Loop scheme"]},{"metadata":{"id":"mH7Tht-DqGyP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"8bec59ff-7f39-41ef-87f4-536276154a8a"},"cell_type":"code","source":["# This way we have randomness and are able to reproduce the behaviour within this cell.\n","np.random.seed(13)\n","\n","def mean_coding(data, feature, target='y'):\n","    '''\n","    In this implementation we get the values and the dictionary as two different steps.\n","    This is just because initially we were ignoring the dictionary as a result variable.\n","    \n","    In this implementation the KFolds use shuffling. If you want reproducibility the cv \n","    could be moved to a parameter.\n","    '''\n","    n_folds = 10 # 外層loop folder數\n","    n_inner_folds = 5 # 內層loop folder數\n","    impact_coded = pd.Series()\n","    \n","    oof_default_mean = data[target].mean() # Gobal mean \n","    \n","    kf = KFold(n_splits=n_folds, shuffle=True)\n","    oof_mean_cv = pd.DataFrame()\n","    split = 0\n","    for infold, oof in kf.split(data[feature]):\n","            impact_coded_cv = pd.Series()\n","            kf_inner = KFold(n_splits=n_inner_folds, shuffle=True)\n","            inner_split = 0\n","            inner_oof_mean_cv = pd.DataFrame()\n","            oof_default_inner_mean = data.iloc[infold][target].mean()# \n","            for infold_inner, oof_inner in kf_inner.split(data.iloc[infold]): # kf_inner \n","                # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n","                oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n","                impact_coded_cv = impact_coded_cv.append(data.iloc[infold].apply(\n","                            lambda x: oof_mean[x[feature]]\n","                                      if x[feature] in oof_mean.index\n","                                      else oof_default_inner_mean\n","                            , axis=1))\n","\n","                # Also populate mapping (this has all group -> mean for all inner CV folds)\n","                inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n","                inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n","                inner_split += 1\n","\n","            # Also populate mapping\n","            oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n","            oof_mean_cv.fillna(value=oof_default_mean, inplace=True)\n","            split += 1\n","            \n","            impact_coded = impact_coded.append(data.iloc[oof].apply(\n","                            lambda x: inner_oof_mean_cv.loc[x[feature]].mean()\n","                                      if x[feature] in inner_oof_mean_cv.index\n","                                      else oof_default_mean\n","                            , axis=1))\n","\n","    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean\n","\n","# Apply the encoding to training and test data, and preserve the mapping\n","impact_coding_map = {}\n","for f in categorical_features:\n","    print(\"Impact coding for {}\".format(f))\n","    train_data[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = mean_coding(train_data, f)\n","    impact_coding_map[f] = (impact_coding_mapping, default_coding)\n","    mapping, default_mean = impact_coding_map[f]\n","    test_data[\"impact_encoded_{}\".format(f)] = test_data.apply(lambda x: mapping[x[f]]\n","                                                                         if x[f] in mapping\n","                                                                         else default_mean\n","                                                                        , axis=1)\n","    print('Corr between {} and target is: {}'.format(f ,np.corrcoef(train_data['y'].values, test_data[\"impact_encoded_{}\".format(f)])[0][1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Impact coding for category_name\n"],"name":"stdout"}]},{"metadata":{"id":"RBpjsjmDqGyW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}
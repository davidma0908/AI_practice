{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gziNjJzn5XKA"
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/1*jX6Gwn1rt4da7e-yUj84IQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xHkobL45XKB"
   },
   "source": [
    "### 請先在terminal執行\n",
    "`pip install --user catboost --no-cache-dir`\n",
    "\n",
    "`pip install --user lightgbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "eE2EJUER5XKD",
    "outputId": "8d35f9d4-dc46-41e3-d753-c8974e09cb39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, psutil\n",
    "\n",
    "\n",
    "def cpuStats():\n",
    "    \"\"\" @author: RDizzl3 @address: https://www.kaggle.com/rdizzl3\"\"\"\n",
    "    print(\"########## CPU STATS ############\")\n",
    "    pid = os.getpid()\n",
    "    print(pid)\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "    print(\"########## CPU STATS ############\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from multiprocessing import Process, Pool\n",
    "import functools\n",
    "\n",
    "import re\n",
    "import unidecode\n",
    "import math\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9KfCQinC5XKJ"
   },
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "train = pd.read_table(PATH + 'train.tsv', engine='c')\n",
    "test = pd.read_table(PATH + 'test.tsv', engine='c')\n",
    "\n",
    "train = train.loc[train.price > 0]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "y = np.log1p(train[\"price\"].values)\n",
    "test_id = test.test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CqhxKOW5XKM"
   },
   "source": [
    "## Helper Function，請執行後忽略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jo97yIg55XKN"
   },
   "outputs": [],
   "source": [
    "Hash_binary = True\n",
    "\n",
    "def handle_missing_inplace(dataset):\n",
    "    dataset['category_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='No description yet', inplace=True)\n",
    "\n",
    "    \n",
    "def preprocess(text): # 這是之前的作業的簡易版\n",
    "    non_alphanums = re.compile(u'[^A-Za-z0-9]+')\n",
    "    # regex for short = re 請參考 http://ccckmit.wikidot.com/regularexpression \n",
    "    \n",
    "    text = unidecode.unidecode(text)\n",
    "    text = str(text).lower()\n",
    "    return u\" \".join(\n",
    "        [x for x in [y for y in non_alphanums.sub(' ', text).strip().split(\" \")]])\n",
    "        # strip split 請參考 http://ericbbs.blogspot.tw/2009/07/python-strip-split.html\n",
    "        # [x for x in.....] 這文言文：是 list comprehension\n",
    "\n",
    "    \n",
    "### 以下是multithread ，請自行忽略 ，多執行緒不在本課程範圍。 \n",
    "\n",
    "def multi_hash(data=None, hash_vec=None, n_jobs=4):\n",
    "\n",
    "    p = Pool(n_jobs)\n",
    "    csr_parts = p.map(hash_vec.fit_transform, np.array_split(data, n_jobs))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return vstack(csr_parts).tocsr\n",
    "\n",
    "def multi_apply(df=None, feat_list=None, func=None, axis=0, raw=True, n_jobs=4):\n",
    "\n",
    "    p = Pool(n_jobs)\n",
    "    f_ = p.map(functools.partial(apply_func, func=func, axis=axis, raw=raw),\n",
    "               np.array_split(df[feat_list], n_jobs))\n",
    "    f_ = pd.concat(f_, axis=0, ignore_index=True)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return f_.values\n",
    "\n",
    "def apply_func_series(data=None, func=None):\n",
    "\n",
    "    return data.apply(func)\n",
    "\n",
    "def multi_apply_series(df=None, feature=None, func=None, n_jobs=4):\n",
    "\n",
    "    p = Pool(n_jobs)\n",
    "    f_ = p.map(functools.partial(apply_func_series, func=func),\n",
    "               np.array_split(df[feature], n_jobs))\n",
    "    f_ = pd.concat(f_, axis=0, ignore_index=True)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return f_.values\n",
    "    \n",
    "\n",
    "def apply_func(data=None, func=None, axis=0, raw=True):\n",
    "\n",
    "    return data.apply(func, axis=axis, raw=raw)\n",
    "\n",
    "\n",
    "def preprocess_text_features(df):\n",
    "\n",
    "    df[\"item_description\"] = multi_apply_series(df=df[[\"item_description\"]],\n",
    "                                                feature=\"item_description\",\n",
    "                                                func=preprocess,\n",
    "                                                n_jobs=4)\n",
    "    df[\"name\"] = multi_apply_series(df=df[[\"name\"]],\n",
    "                                    feature=\"name\",\n",
    "                                    func=preprocess,\n",
    "                                    n_jobs=4)\n",
    "    \n",
    "def get_hashing_features(df, Hash_binary, start_time):\n",
    "    # df = pd.concat([train, test])\n",
    "    dim = 20\n",
    "    ha = HashingVectorizer(\n",
    "        n_features=2 ** dim,\n",
    "        ngram_range=(1, 2),\n",
    "        norm=None,\n",
    "        alternate_sign=False,\n",
    "        binary=Hash_binary\n",
    "        # stop_words='english'\n",
    "    )\n",
    "\n",
    "    X_name = ha.fit_transform(df['name'])\n",
    "    cpuStats()\n",
    "    X_name += ha.fit_transform(df['item_description'])\n",
    "    cpuStats()\n",
    "    \n",
    "    print('[{}] Finished hashing'.format(time.time() - start_time))\n",
    "    return X_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk30L3x85XKQ"
   },
   "source": [
    "## 預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "yiWHTwAO5XKR",
    "outputId": "df74b11e-ab1e-4cf0-fff2-555068ee9318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "14854\n",
      "memory GB: 1.5250625610351562\n",
      "########## CPU STATS ############\n",
      "########## CPU STATS ############\n",
      "14854\n",
      "memory GB: 1.0345611572265625\n",
      "########## CPU STATS ############\n",
      "[203.96181082725525] Finished hashing\n",
      "有多少欄位: 1048576\n",
      "########## CPU STATS ############\n",
      "14854\n",
      "memory GB: 1.4660377502441406\n",
      "########## CPU STATS ############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "handle_missing_inplace(train) # 處理 NaN \n",
    "\n",
    "nrows = train.shape[0]\n",
    "merge = pd.concat([train, test])\n",
    "del train, test \n",
    "gc.collect()\n",
    "\n",
    "preprocess_text_features(df=merge)\n",
    "merge = get_hashing_features(merge, Hash_binary, start_time) # Hash Trick\n",
    "\n",
    "print('有 {} 欄位'.format(merge.shape[1]) )\n",
    "\n",
    "csr_train = merge[:nrows]\n",
    "csr_test = merge[nrows:]\n",
    "del merge\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0oV3ELL5XKX"
   },
   "source": [
    "### 避免Hub，跑太久，使用L1 Selection，選特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "Pt3OF1iT5XKZ",
    "outputId": "2dd51df5-2a45-4fa8-fdf7-557a792b008f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208.7959930896759] Starting SGD l1 selection\n",
      "Features reduced from    1048576 to     446994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('[{}] Starting SGD l1 selection'.format(time.time() - start_time))\n",
    "sgd_l1 = SGDRegressor(max_iter=30, penalty=\"l1\", random_state=1, alpha=1e-6)\n",
    "sgd_l1.fit(csr_train, y)\n",
    "good_feats = np.abs(np.array(sgd_l1.coef_)) > 1e-6 \n",
    "print(\"Features reduced from %10d to %10d\" % (csr_train.shape[1], int(good_feats.sum())))\n",
    "\n",
    "csr_train = csr_train[:, good_feats]\n",
    "csr_test = csr_test[:, good_feats]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCzsP4pL5XKd"
   },
   "source": [
    "### XGBoost Lightgbm Catboost\n",
    "- XGBoost [參數](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)\n",
    "- LightGBM [參數](http://lightgbm.readthedocs.io/en/latest/Parameters.html)\n",
    "- CatBoost [參數](https://tech.yandex.com/catboost/doc/dg/concepts/parameter-tuning-docpage/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YpwI1e-l5XKe"
   },
   "outputs": [],
   "source": [
    "class Xgb(object):\n",
    "    def __init__(self, seed=2018, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 100) # 避免跑太久，所以設100\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        dtrain = xgb.DMatrix(xtra, label=ytra)\n",
    "        dvalid = xgb.DMatrix(xte, label=yte)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds,\n",
    "            watchlist, verbose_eval=20)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "class Lgb(object):\n",
    "    def __init__(self, seed=2018, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 100)# 避免跑太久，所以設100\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        #ytra = ytra.ravel()\n",
    "        #yte = yte.ravel()\n",
    "        dtrain = lgb.Dataset(xtra, label=ytra)\n",
    "        dvalid = lgb.Dataset(xte, label=yte)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.gbdt = lgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(x)\n",
    "\n",
    "class Cat(object):\n",
    "    def __init__(self, seed=2018, params=None):\n",
    "        self.seed = seed\n",
    "        self.param = params\n",
    "        self.nrounds = 100 # 避免跑太久，所以設100\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        self.gbdt = ctb.CatBoostRegressor(depth=4,\n",
    "            iterations=self.nrounds, random_seed=self.seed,\n",
    "            use_best_model=True)\n",
    "\n",
    "        xtra = pd.DataFrame(xtra)\n",
    "        ytra = pd.DataFrame(ytra)\n",
    "        xte = pd.DataFrame(xte)\n",
    "        yte = pd.DataFrame(yte)\n",
    "\n",
    "        self.gbdt.fit(X=xtra, y=ytra, eval_set=(xte, yte),\n",
    "                      use_best_model=True)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XfClWFE5XKh"
   },
   "source": [
    "## Meta KFold with OOF (Out Of Fold)\n",
    "### K折交叉驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E-eVN6cb5XKi"
   },
   "outputs": [],
   "source": [
    "fold = 5 # 手動設置要幾個fold\n",
    "        \n",
    "        # ==== 以下建議搭配slide 圖示會更清楚運作過程 ====\n",
    "        # ==== 以下建議搭配slide 圖示會更清楚運作過程 ====\n",
    "        # ==== 以下建議搭配slide 圖示會更清楚運作過程 ====\n",
    "\n",
    "def oof(model, ntrain, ntest, kf, train, labels, test):\n",
    "    # model, 用的模型\n",
    "    # ntrain, 訓練集的row number\n",
    "    # ntest,  測試集的row number\n",
    "    # kf,     Kfold obj\n",
    "    # train,  訓練集\n",
    "    # labels, 目標\n",
    "    # test    測試集\n",
    "    \n",
    "    # 先配置空間\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((fold, ntest)) # fold X ntest 空間 \n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf): # 開始分割\n",
    "        x_tr = train[train_index]\n",
    "        y_tr = labels[train_index]\n",
    "        x_te = train[test_index]\n",
    "        y_te = labels[test_index]\n",
    "\n",
    "        model.train(x_tr, y_tr, x_te, y_te) # 訓練 (fold-1)個 fold\n",
    "\n",
    "        oof_train[test_index] = model.predict(x_te) # 去預測 train left fold，稱作meta-train\n",
    "        oof_test_skf[i, :] = model.predict(test) # 去預測 test，稱作meta-test\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0) # all folds score 取平均\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ghsor_8j5XKl"
   },
   "source": [
    "### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "98trQ2pI5XKl"
   },
   "outputs": [],
   "source": [
    "def level_1(train, labels, test):\n",
    "    #train = train\n",
    "    #test = test\n",
    "    #labels = labels\n",
    "\n",
    "    ntrain = train.shape[0]\n",
    "    ntest = test.shape[0]\n",
    "\n",
    "    kf = KFold(ntrain, n_folds=fold ,\n",
    "               shuffle=True, random_state=2018)\n",
    "\n",
    "    lgb_params = {}\n",
    "    lgb_params['boosting_type'] = 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['num_leaves'] = 2**5\n",
    "    lgb_params['max_depth'] = 4\n",
    "    lgb_params['feature_fraction'] = 0.9\n",
    "    lgb_params['bagging_fraction'] = 0.95\n",
    "    lgb_params['bagging_freq'] = 5\n",
    "    lgb_params['learning_rate'] = 0.3\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params['booster'] = 'gbtree'\n",
    "    xgb_params['objective'] = 'reg:linear'\n",
    "    xgb_params['learning_rate'] = 0.3\n",
    "    xgb_params['max_depth'] = 4\n",
    "    xgb_params['subsample'] = 0.8\n",
    "    xgb_params['colsample_bytree'] = 0.7\n",
    "    xgb_params['colsample_bylevel'] = 0.7\n",
    "\n",
    "    cat_params = {}\n",
    "    cat_params['learning_rate'] = 0.3\n",
    "    cat_params['depth'] = 3\n",
    "    cat_params['bagging_temperature'] = 0.8\n",
    "    cat_params['loss_function']='RMSE'\n",
    "    cat_params['eval_metric']='RMSE'\n",
    "    \n",
    "    cg = Cat(seed=2018, params=cat_params)\n",
    "    xg = Xgb(seed=2018, params=xgb_params)\n",
    "    lg = Lgb(seed=2018, params=lgb_params)\n",
    "    \n",
    "    ##########################################################################\n",
    "    xg_oof_train, xg_oof_test = oof(xg, ntrain, ntest, kf, train, labels, test)\n",
    "    lg_oof_train, lg_oof_test = oof(lg, ntrain, ntest, kf, train, labels, test)\n",
    "    cg_oof_train, cg_oof_test = oof(cg, ntrain, ntest, kf, train, labels, test)\n",
    "    ##########################################################################\n",
    "    \n",
    "    print(\"CG-CV: {}\".format(mean_squared_error(labels, cg_oof_train)))\n",
    "    print(\"XG-CV: {}\".format(mean_squared_error(labels, xg_oof_train)))\n",
    "    print(\"LG-CV: {}\".format(mean_squared_error(labels, lg_oof_train)))\n",
    "\n",
    "    x_train = np.concatenate((cg_oof_train, xg_oof_train, lg_oof_train), axis=1)\n",
    "    x_test = np.concatenate((cg_oof_test, xg_oof_test, lg_oof_test), axis=1)\n",
    "\n",
    "    np.save(arr=x_train, file='x_concat_train.npy')\n",
    "    np.save(arr=x_test, file='x_concat_test.npy')\n",
    "    np.save(arr=labels, file='y_labels.npy')\n",
    "\n",
    "    return x_train, labels, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvstV4lK5XKo"
   },
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H0m3QDXS5XKp"
   },
   "outputs": [],
   "source": [
    "def level_2():\n",
    "    train = np.load('x_concat_train.npy')\n",
    "    labels = np.load('y_labels.npy')\n",
    "    test = np.load('x_concat_test.npy')\n",
    "\n",
    "    dtrain = xgb.DMatrix(train, label=labels)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params[\"objective\"] = \"reg:linear\"\n",
    "    xgb_params[\"eta\"] = 0.1\n",
    "    xgb_params[\"subsample\"] = 0.9\n",
    "    xgb_params[\"max_depth\"] = 5\n",
    "    xgb_params['eval_metric'] = 'rmse'\n",
    "    xgb_params['min_child_weight'] = 10\n",
    "    xgb_params['seed'] = 2018\n",
    "\n",
    "    res = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=5, seed=2018, stratified=False,\n",
    "                 early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "    best_nrounds = res.shape[0] - 1\n",
    "    cv_mean = res.iloc[-1, 0]\n",
    "    cv_std = res.iloc[-1, 1]\n",
    "\n",
    "    print('')\n",
    "    print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "    bst = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "    preds = np.expm1(bst.predict(dtest)) # 一開始把目標取了np.log1p()，現在inverse回去\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "xhkBJqHr5XKr",
    "outputId": "0bc05bbb-56ae-4653-9796-00c320326422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.88501\teval-rmse:1.88423\n",
      "[1]\ttrain-rmse:1.41393\teval-rmse:1.4132\n",
      "[2]\ttrain-rmse:1.11129\teval-rmse:1.11056\n",
      "[3]\ttrain-rmse:0.926055\teval-rmse:0.925453\n",
      "[4]\ttrain-rmse:0.817426\teval-rmse:0.816743\n",
      "[5]\ttrain-rmse:0.757215\teval-rmse:0.756551\n",
      "[6]\ttrain-rmse:0.723132\teval-rmse:0.722545\n",
      "[7]\ttrain-rmse:0.704646\teval-rmse:0.704118\n",
      "[8]\ttrain-rmse:0.694136\teval-rmse:0.693649\n",
      "[9]\ttrain-rmse:0.68765\teval-rmse:0.687339\n",
      "[10]\ttrain-rmse:0.682583\teval-rmse:0.6824\n",
      "[11]\ttrain-rmse:0.678968\teval-rmse:0.678809\n",
      "[12]\ttrain-rmse:0.676046\teval-rmse:0.675904\n",
      "[13]\ttrain-rmse:0.673466\teval-rmse:0.673319\n",
      "[14]\ttrain-rmse:0.671143\teval-rmse:0.670928\n",
      "[15]\ttrain-rmse:0.668533\teval-rmse:0.668357\n",
      "[16]\ttrain-rmse:0.666427\teval-rmse:0.666331\n",
      "[17]\ttrain-rmse:0.664565\teval-rmse:0.664521\n",
      "[18]\ttrain-rmse:0.662856\teval-rmse:0.662915\n",
      "[19]\ttrain-rmse:0.661313\teval-rmse:0.661537\n",
      "[20]\ttrain-rmse:0.659742\teval-rmse:0.659943\n",
      "[21]\ttrain-rmse:0.658045\teval-rmse:0.658273\n",
      "[22]\ttrain-rmse:0.65655\teval-rmse:0.656831\n",
      "[23]\ttrain-rmse:0.655212\teval-rmse:0.655402\n",
      "[24]\ttrain-rmse:0.653638\teval-rmse:0.653796\n",
      "[25]\ttrain-rmse:0.652411\teval-rmse:0.652645\n",
      "[26]\ttrain-rmse:0.651179\teval-rmse:0.651441\n",
      "[27]\ttrain-rmse:0.649437\teval-rmse:0.649738\n",
      "[28]\ttrain-rmse:0.648199\teval-rmse:0.648511\n",
      "[29]\ttrain-rmse:0.646778\teval-rmse:0.647124\n",
      "[30]\ttrain-rmse:0.645697\teval-rmse:0.646085\n",
      "[31]\ttrain-rmse:0.644658\teval-rmse:0.645104\n",
      "[32]\ttrain-rmse:0.643464\teval-rmse:0.643911\n",
      "[33]\ttrain-rmse:0.642375\teval-rmse:0.642811\n",
      "[34]\ttrain-rmse:0.641413\teval-rmse:0.641888\n",
      "[35]\ttrain-rmse:0.640478\teval-rmse:0.640992\n",
      "[36]\ttrain-rmse:0.639386\teval-rmse:0.639909\n",
      "[37]\ttrain-rmse:0.638285\teval-rmse:0.638778\n",
      "[38]\ttrain-rmse:0.637219\teval-rmse:0.637737\n",
      "[39]\ttrain-rmse:0.636259\teval-rmse:0.636891\n",
      "[40]\ttrain-rmse:0.635462\teval-rmse:0.636121\n",
      "[41]\ttrain-rmse:0.63464\teval-rmse:0.635274\n",
      "[42]\ttrain-rmse:0.633586\teval-rmse:0.634277\n",
      "[43]\ttrain-rmse:0.632815\teval-rmse:0.633566\n",
      "[44]\ttrain-rmse:0.63202\teval-rmse:0.632806\n",
      "[45]\ttrain-rmse:0.631198\teval-rmse:0.632077\n",
      "[46]\ttrain-rmse:0.630267\teval-rmse:0.631179\n",
      "[47]\ttrain-rmse:0.629355\teval-rmse:0.630275\n",
      "[48]\ttrain-rmse:0.628707\teval-rmse:0.629649\n",
      "[49]\ttrain-rmse:0.62804\teval-rmse:0.629009\n",
      "[50]\ttrain-rmse:0.627401\teval-rmse:0.628333\n",
      "[51]\ttrain-rmse:0.626703\teval-rmse:0.62766\n",
      "[52]\ttrain-rmse:0.626036\teval-rmse:0.627037\n",
      "[53]\ttrain-rmse:0.625425\teval-rmse:0.626436\n",
      "[54]\ttrain-rmse:0.62467\teval-rmse:0.625675\n",
      "[55]\ttrain-rmse:0.624043\teval-rmse:0.625038\n",
      "[56]\ttrain-rmse:0.623035\teval-rmse:0.624046\n",
      "[57]\ttrain-rmse:0.622284\teval-rmse:0.623272\n",
      "[58]\ttrain-rmse:0.621581\teval-rmse:0.622611\n",
      "[59]\ttrain-rmse:0.621047\teval-rmse:0.622063\n",
      "[60]\ttrain-rmse:0.620426\teval-rmse:0.62144\n",
      "[61]\ttrain-rmse:0.619869\teval-rmse:0.620932\n",
      "[62]\ttrain-rmse:0.619228\teval-rmse:0.620266\n",
      "[63]\ttrain-rmse:0.618623\teval-rmse:0.619646\n",
      "[64]\ttrain-rmse:0.618098\teval-rmse:0.61916\n",
      "[65]\ttrain-rmse:0.61755\teval-rmse:0.618681\n",
      "[66]\ttrain-rmse:0.617004\teval-rmse:0.618195\n",
      "[67]\ttrain-rmse:0.616529\teval-rmse:0.61775\n",
      "[68]\ttrain-rmse:0.616052\teval-rmse:0.617277\n",
      "[69]\ttrain-rmse:0.615461\teval-rmse:0.61674\n",
      "[70]\ttrain-rmse:0.614968\teval-rmse:0.616302\n",
      "[71]\ttrain-rmse:0.614403\teval-rmse:0.61575\n",
      "[72]\ttrain-rmse:0.61386\teval-rmse:0.615236\n",
      "[73]\ttrain-rmse:0.613406\teval-rmse:0.614778\n",
      "[74]\ttrain-rmse:0.612795\teval-rmse:0.614197\n",
      "[75]\ttrain-rmse:0.612068\teval-rmse:0.613431\n",
      "[76]\ttrain-rmse:0.611534\teval-rmse:0.612893\n",
      "[77]\ttrain-rmse:0.610926\teval-rmse:0.612289\n",
      "[78]\ttrain-rmse:0.6104\teval-rmse:0.611796\n",
      "[79]\ttrain-rmse:0.609991\teval-rmse:0.611411\n",
      "[80]\ttrain-rmse:0.609459\teval-rmse:0.610909\n",
      "[81]\ttrain-rmse:0.608949\teval-rmse:0.610399\n",
      "[82]\ttrain-rmse:0.608458\teval-rmse:0.609943\n",
      "[83]\ttrain-rmse:0.60781\teval-rmse:0.60933\n",
      "[84]\ttrain-rmse:0.607388\teval-rmse:0.608896\n",
      "[85]\ttrain-rmse:0.606915\teval-rmse:0.608491\n",
      "[86]\ttrain-rmse:0.60644\teval-rmse:0.608015\n",
      "[87]\ttrain-rmse:0.606042\teval-rmse:0.607614\n",
      "[88]\ttrain-rmse:0.605645\teval-rmse:0.607235\n",
      "[89]\ttrain-rmse:0.605103\teval-rmse:0.606689\n",
      "[90]\ttrain-rmse:0.604683\teval-rmse:0.606297\n",
      "[91]\ttrain-rmse:0.604319\teval-rmse:0.605925\n",
      "[92]\ttrain-rmse:0.603933\teval-rmse:0.605538\n",
      "[93]\ttrain-rmse:0.603551\teval-rmse:0.605218\n",
      "[94]\ttrain-rmse:0.603059\teval-rmse:0.604791\n",
      "[95]\ttrain-rmse:0.602632\teval-rmse:0.604333\n",
      "[96]\ttrain-rmse:0.602269\teval-rmse:0.604013\n",
      "[97]\ttrain-rmse:0.601899\teval-rmse:0.603681\n",
      "[98]\ttrain-rmse:0.601473\teval-rmse:0.603254\n",
      "[99]\ttrain-rmse:0.601116\teval-rmse:0.602903\n",
      "[0]\ttrain-rmse:1.88426\teval-rmse:1.88693\n",
      "[1]\ttrain-rmse:1.41321\teval-rmse:1.41573\n",
      "[2]\ttrain-rmse:1.11062\teval-rmse:1.11283\n",
      "[3]\ttrain-rmse:0.92483\teval-rmse:0.926794\n",
      "[4]\ttrain-rmse:0.817143\teval-rmse:0.818824\n",
      "[5]\ttrain-rmse:0.756595\teval-rmse:0.757975\n",
      "[6]\ttrain-rmse:0.723977\teval-rmse:0.725149\n",
      "[7]\ttrain-rmse:0.705171\teval-rmse:0.706311\n",
      "[8]\ttrain-rmse:0.693723\teval-rmse:0.694592\n",
      "[9]\ttrain-rmse:0.686888\teval-rmse:0.687754\n",
      "[10]\ttrain-rmse:0.682352\teval-rmse:0.682915\n",
      "[11]\ttrain-rmse:0.678931\teval-rmse:0.679469\n",
      "[12]\ttrain-rmse:0.676099\teval-rmse:0.676612\n",
      "[13]\ttrain-rmse:0.673701\teval-rmse:0.674261\n",
      "[14]\ttrain-rmse:0.670948\teval-rmse:0.671456\n",
      "[15]\ttrain-rmse:0.668763\teval-rmse:0.669281\n",
      "[16]\ttrain-rmse:0.666923\teval-rmse:0.667442\n",
      "[17]\ttrain-rmse:0.66467\teval-rmse:0.665145\n",
      "[18]\ttrain-rmse:0.662812\teval-rmse:0.663362\n",
      "[19]\ttrain-rmse:0.661168\teval-rmse:0.661702\n",
      "[20]\ttrain-rmse:0.65974\teval-rmse:0.660213\n",
      "[21]\ttrain-rmse:0.658211\teval-rmse:0.658718\n",
      "[22]\ttrain-rmse:0.656727\teval-rmse:0.65725\n",
      "[23]\ttrain-rmse:0.655188\teval-rmse:0.655734\n",
      "[24]\ttrain-rmse:0.653706\teval-rmse:0.654221\n",
      "[25]\ttrain-rmse:0.652367\teval-rmse:0.652968\n",
      "[26]\ttrain-rmse:0.651237\teval-rmse:0.651884\n",
      "[27]\ttrain-rmse:0.650113\teval-rmse:0.650813\n",
      "[28]\ttrain-rmse:0.648894\teval-rmse:0.649617\n",
      "[29]\ttrain-rmse:0.647795\teval-rmse:0.648453\n",
      "[30]\ttrain-rmse:0.646586\teval-rmse:0.647287\n",
      "[31]\ttrain-rmse:0.645409\teval-rmse:0.646121\n",
      "[32]\ttrain-rmse:0.644284\teval-rmse:0.644965\n",
      "[33]\ttrain-rmse:0.643292\teval-rmse:0.643983\n",
      "[34]\ttrain-rmse:0.642192\teval-rmse:0.642917\n",
      "[35]\ttrain-rmse:0.641021\teval-rmse:0.641811\n",
      "[36]\ttrain-rmse:0.639994\teval-rmse:0.640822\n",
      "[37]\ttrain-rmse:0.638969\teval-rmse:0.639758\n",
      "[38]\ttrain-rmse:0.638045\teval-rmse:0.638836\n",
      "[39]\ttrain-rmse:0.637152\teval-rmse:0.637894\n",
      "[40]\ttrain-rmse:0.635995\teval-rmse:0.636632\n",
      "[41]\ttrain-rmse:0.635154\teval-rmse:0.63576\n",
      "[42]\ttrain-rmse:0.634432\teval-rmse:0.635111\n",
      "[43]\ttrain-rmse:0.633711\teval-rmse:0.634426\n",
      "[44]\ttrain-rmse:0.632947\teval-rmse:0.633731\n",
      "[45]\ttrain-rmse:0.632202\teval-rmse:0.632949\n",
      "[46]\ttrain-rmse:0.631314\teval-rmse:0.632043\n",
      "[47]\ttrain-rmse:0.630217\teval-rmse:0.630992\n",
      "[48]\ttrain-rmse:0.629467\teval-rmse:0.630196\n",
      "[49]\ttrain-rmse:0.628706\teval-rmse:0.629499\n",
      "[50]\ttrain-rmse:0.628036\teval-rmse:0.628795\n",
      "[51]\ttrain-rmse:0.627398\teval-rmse:0.628144\n",
      "[52]\ttrain-rmse:0.62667\teval-rmse:0.627374\n",
      "[53]\ttrain-rmse:0.625865\teval-rmse:0.626612\n",
      "[54]\ttrain-rmse:0.624869\teval-rmse:0.625647\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    x_train, labels, x_test = level_1(csr_train, y, csr_test)\n",
    "    preds = level_2()\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = test_id\n",
    "    sub['price'] = preds\n",
    "    sub.to_csv('stacking.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrI521Bm5XKt"
   },
   "source": [
    "- 我們已同意將完整版solution開源，如果您有興趣 [here](https://github.com/goldentom42/kaggle_mercari_2017/blob/master/mercari.py)\n",
    "    - 完整版因為資源限制，所以跟Excercise 99%作法不同，也更powerful。\n",
    "- Kudos to Teammates [Olivier](), [Mark Peng](), [Rand Xie](), [Yifan Xie]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H9cDEkvx5XKu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "06_Pratice_stacking.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

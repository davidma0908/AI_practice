{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Basic package'''\n",
    "import os\n",
    "# 告訴系統要第幾張卡被看到。 Ex. 硬體總共有8張顯卡，以下設定只讓系統看到第1張顯卡\n",
    "# 若沒設定，則 Tensorflow 在運行時，預設會把所有卡都佔用\n",
    "# 要看裝置內顯卡數量及目前狀態的話，請在終端機內輸入 \"nvidia-smi\"\n",
    "# 若你的裝置只有一張顯卡可以使用，可以忽略此設定\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import queue\n",
    "import cv2          #影像處理\n",
    "import scipy.misc   #影像處理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm #進度條\n",
    "import matplotlib.pyplot as plt #繪圖\n",
    "\n",
    "\n",
    "# 自定義 library\n",
    "from generator import data_generators\n",
    "from callbacks import *\n",
    "\n",
    "\n",
    "'''Tensorflow package'''\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as slimNet\n",
    "\n",
    "\n",
    "'''Data augmentation package'''\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "img_size = 200 # 建議和 pre-trained 訓練的大小相近\n",
    "num_class = 2  # 資料集總共有幾個類別\n",
    "\n",
    "# model\n",
    "batch_size = num_class*48 # generator 在取訓練資料的時候，會做類別平衡的動作 (batch data 裡面每個類別影像的數量一樣多)\n",
    "                          # batch size 要取類別數量的倍數\n",
    "nb_epoch = 150\n",
    "n_batch = 300\n",
    "fold = str(0) \n",
    "model_name = 'pretrain_'+fold # 為自己的模型取個名字 :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(id_list, num_class, aug = False):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    file = []\n",
    "\n",
    "    for idx, row in id_list.iterrows():\n",
    "        kind = row[1]\n",
    "        path = row[0]\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = img[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "        \n",
    "        if aug:\n",
    "            seq = iaa.Sequential([\n",
    "                    iaa.Fliplr(0.5),               # 左右翻轉\n",
    "                    iaa.Flipud(0.5),               # 上下翻轉\n",
    "                    iaa.Affine(rotate=(-180, 180), # 旋轉\n",
    "                    scale=(0.6, 1.4),              # 縮放\n",
    "                    mode = 'wrap',                 # 影像翻轉造成區塊缺值的補值方式\n",
    "                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)})]) # 平移\n",
    "            img = seq.augment_image(img)\n",
    "\n",
    "        # zero-mean\n",
    "        # pre-trained model 使用 ImageNet 做訓練\n",
    "        # ImageNet 的所有影像 RGB 平均值 [123.68, 116.78, 103.94]\n",
    "        img = img.astype('float32') - np.array([123.68, 116.78, 103.94]) \n",
    "        \n",
    "        \n",
    "        #append to list\n",
    "        x.append(img)\n",
    "        y.append(kind)\n",
    "        \n",
    "        file.append(path)\n",
    "    try:\n",
    "        x = np.array(x)\n",
    "    except:\n",
    "        print([i.shape for i in x])\n",
    "    y = np.eye(num_class)[np.array(y)] # one-hot encoding\n",
    "\n",
    "    return [x],y,file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_name' : model_name,\n",
    "    'reduce_lr' : ReduceLROnPlateau(lr=1.7e-4, factor=0.5, patience=3),\n",
    "    'earlystop' : EarlyStopping(min_delta = 1e-4, patience= 10),\n",
    "    'checkpoint' : Model_checkpoint(os.path.join('model', model_name)),\n",
    "    'train_batch_log' : History(['loss']),\n",
    "    'val_batch_log' : History(['loss']),\n",
    "    'history' : {\n",
    "        'train_loss':[],\n",
    "        'val_loss':[]\n",
    "    },\n",
    "    'testing' : {\n",
    "        'y_true' : [],\n",
    "        'y_pred' : [],\n",
    "        'files'   : []\n",
    "    }\n",
    "}\n",
    "\n",
    "callback_dict = {\n",
    "    'on_session_begin':[], # start of a session\n",
    "    'on_batch_begin':[], # start of a training batch\n",
    "    'on_batch_end':[], # end of a training batch\n",
    "    'on_epoch_begin':[], # start of a epoch\n",
    "    'on_epoch_end':[\n",
    "        model_dict['reduce_lr'],\n",
    "        model_dict['earlystop'],\n",
    "        model_dict['checkpoint']\n",
    "    ], # end of a epoch\n",
    "    'on_session_end':[] # end of a session\n",
    "}\n",
    "callback_manager = Run_collected_functions(callback_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train/test set\n",
    "test_dog = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"test_dog_\" + fold +\".csv\"))\n",
    "test_cat = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"test_cat_\" + fold +\".csv\"))\n",
    "\n",
    "train_dog = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"train_dog_\" + fold +\".csv\"))\n",
    "train_cat = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"train_cat_\" + fold +\".csv\"))\n",
    "\n",
    "val_dog = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"val_dog_\" + fold +\".csv\"))\n",
    "val_cat = pd.read_csv(os.path.join(\"data_list/cat_dog/k_fold\",\"val_cat_\" + fold +\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data_generators 參數說明\n",
    "\n",
    "bz: batch size\n",
    "\n",
    "dataframes:\n",
    "    dataframes for generators\n",
    "    should inpt in the format\n",
    "    [\n",
    "    [kind1_train, kind1_val, kind1_test],\n",
    "    [kind2_train, kind2_val, kind2_test]\n",
    "    ]\n",
    "\n",
    "num_class: number classes of data\n",
    "\n",
    "preprocess: preprocess function\n",
    "            will receive a dataframe\n",
    "            and should out put in the format\n",
    "            [x1, x2], y, file/id\n",
    "'''\n",
    "\n",
    "generators = data_generators(batch_size, [[train_dog, val_dog, test_dog], [train_cat, val_cat, test_cat]], num_class, \n",
    "                             preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators.load_val() # validation data 不多且每個 epoch 的資料固定，可以預先全部載入記憶體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators.start_train_threads() # 開啟訓練集的執行緒 (支援多執行緒，但為了不造成伺服器負擔，預設只開一個執行緒)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 建立靜態圖 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x, num_class):\n",
    "    x = tf.reduce_mean(x, [1,2]) # global average pooling\n",
    "    x = tf.layers.dense(x, num_class)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''graph\n",
    "\n",
    "這部分就像一張計畫圖一樣，定義我們計算的流程\n",
    "此部分沒辦法直接被執行，必須靠 session 才能實際執行運算\n",
    "\n",
    "'''\n",
    "\n",
    "main_graph = tf.Graph()\n",
    "sess = tf.Session(graph=main_graph)\n",
    "with main_graph.as_default():\n",
    "    #### optimizer ####\n",
    "    lr = tf.placeholder(tf.float32, shape=[])\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "        \n",
    "    #### placeholder ####\n",
    "    input_img = tf.placeholder(dtype=tf.float32, shape=(None, img_size, img_size, 3))\n",
    "    y_true = tf.placeholder(dtype=tf.float32, shape=(None, num_class))\n",
    "    is_training = tf.placeholder(dtype=tf.bool, shape=[])\n",
    "    \n",
    "    #### model ####\n",
    "    with slim.arg_scope(slimNet.resnet_utils.resnet_arg_scope(batch_norm_decay=0.99)):\n",
    "        _, layers_dict = slimNet.resnet_v2.resnet_v2_50(input_img, global_pool=False, is_training=is_training)\n",
    "        conv_output = layers_dict['resnet_v2_50/block4']\n",
    "    \n",
    "    with tf.variable_scope('CLASS_1'):\n",
    "        pred = classifier(conv_output, num_class)\n",
    "        pred_softmax = tf.nn.softmax(pred)\n",
    "    \n",
    "    #### loss ####\n",
    "    loss = tf.losses.softmax_cross_entropy(y_true, pred)\n",
    "    \n",
    "    #### udpate ####\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) #使用內建的 batch normalization layer, 必須執行\n",
    "    with tf.control_dependencies(update_ops):               #tf.GraphKeys.UPDATE_OPS 才會更新到 BN 層的 mean, variance\n",
    "        update = optimizer.minimize(loss) \n",
    "        \n",
    "    #### other ####\n",
    "    var_list = tf.trainable_variables() # 與 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) 相同    \n",
    "    saver = tf.train.Saver() # 處理模型儲存、載入\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 初始化模型 | 載入模型參數 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### initialize model ####\n",
    "sess.run(init)\n",
    "\n",
    "#### load weights from pre-train model ####\n",
    "saver_restore = tf.train.Saver([v for v in var_list if 'resnet_v2_50' in v.name])\n",
    "saver_restore.restore(sess, 'tf_pretrain_model/resnet_v2_50.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 實際執行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch_bar = tqdm(range(nb_epoch), desc=\"epoch\", unit=\"epoch\")\n",
    "for epoch in epoch_bar:\n",
    "\n",
    "    ### train ###\n",
    "    train_batch_bar = tqdm(range(n_batch), desc=\"train_batch\", unit=\"batch\", leave=False)\n",
    "\n",
    "    for batch in train_batch_bar:\n",
    "        x, y = generators.train_queue.get()\n",
    "        \n",
    "        # 執行 loss & update (train)\n",
    "        _, train_loss = sess.run([update, loss], feed_dict={input_img:x[0], y_true:y, \n",
    "                                                           is_training:True, lr:model_dict['reduce_lr'].lr})\n",
    "        model_dict['train_batch_log'].push({'loss':train_loss})\n",
    "\n",
    "    model_dict['history']['train_loss'].append(model_dict['train_batch_log'].avg_value('loss'))\n",
    "    model_dict['train_batch_log'].reset()\n",
    "\n",
    "    ### val ###\n",
    "    val_batch_bar = tqdm(generators.iter_val(), total=generators.val_len, desc=\"val_batch\" , unit=\"batch\", leave=False)\n",
    "\n",
    "    for x, y, length in val_batch_bar:\n",
    "        # 執行 loss (val)\n",
    "        # 小提醒：Restnet model 有使用 batch normalization。所以在非 training 階段， \n",
    "        # is_training要記得設定為 False。這樣 BN 層內的 mean, variance 才不會更新。\n",
    "        val_loss, = sess.run([loss], feed_dict={input_img: x[0], y_true: y,\n",
    "                                                is_training: False})\n",
    "        \n",
    "        model_dict['val_batch_log'].push({'loss':val_loss}, length)\n",
    "\n",
    "\n",
    "    model_dict['history']['val_loss'].append(model_dict['val_batch_log'].avg_value('loss'))\n",
    "    model_dict['val_batch_log'].reset()\n",
    "\n",
    "    ### callback ###\n",
    "    print('Epoch: {}/{}'.format(epoch,nb_epoch))\n",
    "    print('trai loss: {} | val loss: {}'.format(model_dict['history']['train_loss'][-1], \n",
    "                                                model_dict['history']['val_loss'][-1]))\n",
    "    print('learning rate: ', model_dict['reduce_lr'].lr)\n",
    "    print()\n",
    "    \n",
    "    ### draw loss curve ###\n",
    "    plt.plot(model_dict['history']['train_loss'], label='train_loss')\n",
    "    plt.plot(model_dict['history']['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    callback_manager.run_on_epoch_end(val_loss = model_dict['history']['val_loss'][-1],\n",
    "                                      sess = sess,\n",
    "                                      saver = saver,\n",
    "                                      nth_epoch = epoch)\n",
    "    if model_dict['earlystop'].stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' load model '''\n",
    "saver.restore(sess, os.path.join('model', model_name) + '.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, file in generators.get_test_data():\n",
    "    y_pred = sess.run(pred_softmax, feed_dict={input_img: x[0], is_training: False})\n",
    "    \n",
    "    model_dict['testing']['y_true'].extend(y[:, 1].tolist())\n",
    "    model_dict['testing']['y_pred'].extend(y_pred[:, 1].tolist())\n",
    "    model_dict['testing']['files'].extend(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"files\":model_dict['testing']['files'],\n",
    "                   \"y_true\":model_dict['testing']['y_true'],\n",
    "                   \"y_pred\":model_dict['testing']['y_pred']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(df['y_true'], df['y_pred'].round())\n",
    "print('Accuracy on testing set is {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
